{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a0d7c68",
   "metadata": {},
   "source": [
    "# Identifying High-risk Areas for Theft in London using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cdf676",
   "metadata": {},
   "source": [
    "***\n",
    "#### Preparation\n",
    "\n",
    "- See project in Github: [Github link](https://github.com/meimao76/006assessment)\n",
    "\n",
    "- Number of words: ***\n",
    "\n",
    "- Runtime: *** hours (*Memory 10 GB, CPU Intel i7-10700 CPU @2.90GHz*)\n",
    "\n",
    "- Coding environment: VS Code + Python 3.12 (Windows 11)\n",
    "\n",
    "- License: this notebook is made available under the [Creative Commons Attribution license](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "- Used packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0131c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data cleaning and processing\n",
    "import pandas as pd\n",
    "import osmnx as ox # OSMnx is a Python package to get access to geospatial features from OpenStreetMap. (Boeing, G. 2024)\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be060d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee86b88",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "\n",
    "1. [Literature review](#literature-review)\n",
    "\n",
    "1. [Research questions](#Research-questions)\n",
    "\n",
    "1. [Methodology](#Methodology)\n",
    "\n",
    "1. [Data](#Data)\n",
    "\n",
    "1. [Results](#Results)\n",
    "\n",
    "1. [Discussion and conclusion](#discussion-and-conclusion)\n",
    "\n",
    "1. [References](#References)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ccea80",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Urban safety remains a fundamental concern for cities worldwide, with crime posing persistent challenges to social stability and quality of life. According to a set of Office for Natinal Statistics (ONS) crime data covering the 12 months up to September 2024, London -as the capital of UK- has one of the lowest rates of violent crime and violent crime with injury but also the highest overall rate of crime per 1,000 people in its population. A main contributor for this situation is the high volume of various theft crime.(Hill, 2025) \n",
    "\n",
    "Thus, in order to better protect citizens' property, it is essential to identify and predict when and where theft crimes are most likely to occur across different parts of London.\n",
    "\n",
    "This reseach focuses on finding a machine learning model that performs better in predicting theft risk across London. With open data provided by Metropolitan Police Service (MPS) and ONS, this research seeks to uncover key socioeconomic elements that influence high-risk area distributions.\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6178351",
   "metadata": {},
   "source": [
    "## Literature review\n",
    "\n",
    "Crime has been a key topic in reseach, many have proved that it's not randomly distributed, but shaped by underlying socio-economic conditions and spatial processes. Classical theories like Routine Activity Theory (Cohen and Felson, 1979) have long guided statistical modelling of crime, often through logic regression models linking crime rates to elements like population, housing, educaation and deprivation (Glasson and Cozens, 2011; Hojman, 2004).\n",
    "\n",
    "Machine learning (ML) offered a more effective way to predicting crime. Models like XGBoost and random forest can capture non-linear and high-dimensional relationships, usually outperforming traditional models in terms of predictive power (Yin, 2022; Yunus and Loo, 2024). Despite their accuracy, these \"black-box\" models have been criticized for lacking interpretability—making them difficult to apply in policy-making and urban governance (Mandalapu et al., 2023).\n",
    "\n",
    "To address this, Zhang et al. (2022) applied XGBoost combined with SHAP (Shapley Additive exPlanations) to predict crime rate, showing that the proportion of non-local residents and age group contribute the most to crime prediction. \n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28114904",
   "metadata": {},
   "source": [
    "## Research questions\n",
    "\n",
    "According to previous studies, this study focusing on theft in London, aims to investigate whether interpretable machine learning methods can help to identify and predict crime hotspots, and explain the key drivers of crime rate.\n",
    "\n",
    "To achieve this goal, the study is divided into three research questions:\n",
    "\n",
    "1. Compared to traditional statistical methods, do machine learning models significantly improve the accuracy of predicting the risk of theft across different areas of London?\n",
    "\n",
    "2. What are the most strongly influencing factors associated with theft risk?\n",
    "\n",
    "3. How can contributions of the factors be interpreted in different areas of London using machine learning model?\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b986529",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "In order to better compare the effectiveness of traditional statistical and machine learning models in predicting theft risk in London, this reseach choose Ordinary Least Squares (OLS) regression and eXtreme Gradient Boosting (XGBoost) model as the representative of both kinds.\n",
    "\n",
    "### Crime Rate Prediction\n",
    "\n",
    "Traditional statistical methods remain popular for crime prediction and analysis (Yue and Chen, 2025). With a straightforward mathematical foundation and the ability to assign interpretable weights to different variables, OLS is considered as one of the simplest model for parameter estimation in data-driven crime analysis.(Junxiang Yin, 2022)\n",
    "\n",
    "In recent years, machine learning models have been widely used in crime analysis. Among various machine learning algorithms, XGBoost (Extreme Gradient Boosting) was selected due to its superior performance on tabular data and its capacity for handling nonlinear relationships. Compared with Random Forest, XGboost offers more efficient training through gradient boosting. Other ML methods, such as neural networks or K-nearest neighbors, were not chosen for this research due to they have relatively high demands of data size and low interpretability.\n",
    "\n",
    "### Feature Interpretation\n",
    "\n",
    "In the OLS model, feature interpretation is reflected through regression coefficients. Each coefficient represents the marginal effect of a one-unit change in the corresponding variable on the predicted theft rate. Significance tests (p-values) were used to assess the statistical reliability of each coefficient.\n",
    "\n",
    "In order to interpret feature importance of XGBoost, this study employs SHAP (SHapley Additive Explanations). SHAP values allow for both global analysis highlighting the most influential features across all observations, and local interpretation explaining why specific areas have higher or lower predicted theft rates. SHAP belongs to the method of post-event interpretation of models. Its core idea is to calculate the marginal contribution of features to the model output, and then interpret the \"black box model\" from both the global and local levels.(Retzlaff et al., 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c047a8",
   "metadata": {},
   "source": [
    "![image.png](./flowmapdraft.drawio2.png)\n",
    "\n",
    "**Figure 1.** Methodology\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    " ***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d815aec",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "### Data Source\n",
    "\n",
    "This research combines multiple datasets related to crime, demographics, housing, and deprivation, aggregated at the LSOA (Lower Super Output Area) level in London. The research based on data from 2015-2019 to avoid the influce of Covid-19 after 2020.\n",
    "\n",
    "All data were spatially joined to [LSOA boundaries 2011](https://data.london.gov.uk/dataset/statistical-gis-boundary-files-london). Although the crime dataset was provided under the LSOA 2021 structure, only records that matched with the 2011 boundary were retained. A total of 4653 lsoas were used, resulting in a sample size of the data set of 23265 (4653*5=23265) observations.\n",
    "\n",
    "The main target, theft rate per 1000 people, was calculated from the Metropolitan Police’s Crime records, sourced from the [London Datastore](https://data.london.gov.uk/dataset/recorded_crime_summary). \n",
    "\n",
    "The predicting variables (Table 1) were selected based on prior studies (e.g., Zhang et al., 2022; Hojman, 2004) suggesting socio-economic and urban factors significantly influence theft risk. Thus, this study choose the supporting dataset like [population density](https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/lowersuperoutputareapopulationdensity) and [housing price](https://www.ons.gov.uk/peoplepopulationandcommunity/housing/datasets/medianpricepaidbylowerlayersuperoutputareahpssadataset46) from ONS, as well as the [Index of Multiple Deprivation (IMD)](https://www.gov.uk/government/statistics/english-indices-of-deprivation-2019) from UK government. \n",
    "\n",
    "Population density and POI counts capture exposure and activity levels, while housing prices, vulnerable group proportion and scores for several domains of deprivation reflect socio-economic vulnerability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e70cf9",
   "metadata": {},
   "source": [
    "**Table 1.** Used Variables\n",
    "\n",
    "| Variable | Type | Description | Notes |\n",
    "|----------|------|-------------|-------|\n",
    "| Theft_Rate_per1k | Numeric | Theft rate per 1000 people. Used as dependent var. | Theft counts/Population |\n",
    "| Population_Density | Numeric | Number of people per square kilometer. | Given by ONS |\n",
    "| Vulnerable_Ratio | Numeric | Proportion of elderly and young people. |  Population between 0-15 & 65-/Population  |\n",
    "| House_Price | Numeric | Median housie price. |  Given by ONS  |\n",
    "| Income_Score_rate | Numeric | Proportion of the population experiencing deprivation relating to low income. | Given by Gov.uk |\n",
    "| Employment_Score_rate | Numeric | Proportion of the working-age population in an area involuntarily excluded from the labour market. | Given by Gov.uk |\n",
    "| Education,_Skills_and_Training_Score | Numeric |  Lack of attainment and skills in the local population. | Given by Gov.uk |\n",
    "| Health_Deprivation_and_Disability_Score | Numeric | Risk of premature death and the impairment of quality of life through poor physical or mental health | Given by Gov.uk |\n",
    "| Barriers_to_Housing_and_Services_Score | Numeric | Physical and financial accessibility of housing and local services. | Given by Gov.uk |\n",
    "| Living_Environment_Score | Numeric | Quality of the local environment. | Given by Gov.uk |\n",
    "| tran_poi_count | Numeric | Number of transportations. | Count from OSM |\n",
    "| shop_poi_count | Numeric | Number of shops. | Count from OSM |\n",
    "| LSOA_Code | Categorical | Lower Super Output Area code. Used for spatial join. | Given by London Datastore |\n",
    "| Year | numeric | Year of observation. | 2015-2019 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d33ae75",
   "metadata": {},
   "source": [
    "\n",
    "### Data Cleaning and Preprocessing\n",
    "\n",
    "The raw dataset contains many years of data and multiple metrics, and the following code and analysis helped with the collection and cleaning of the data.\n",
    "\n",
    "1. Crime data: \n",
    "Crime count data is provided monthly. Main task is to calculate the total counts per year for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46a90cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24940, 3)\n",
      "   LSOA Code  Year  Theft Count\n",
      "0  E01000006  2015            3\n",
      "1  E01000006  2016            8\n"
     ]
    }
   ],
   "source": [
    "# read raw crime data\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/meimao76/006assessment/refs/heads/master/data/MPS_LSOA_Level_Crime_(Historical).csv\")\n",
    "\n",
    "# Filter major_category as Theft\n",
    "df_theft = df[df[\"Major Category\"].str.upper().str.contains(\"THEFT\")]\n",
    "\n",
    "# Filter data between 201501-201512\n",
    "date_cols = [col for col in df_theft.columns if col.isdigit()]\n",
    "date_cols = [col for col in date_cols if \"201501\" <= col <= \"201912\"]\n",
    "\n",
    "# only keep lsoa column and time\n",
    "df_filtered = df_theft[[\"LSOA Code\"] + date_cols]\n",
    "\n",
    "# turn the dataset into long format\n",
    "df_long = pd.melt(\n",
    "    df_filtered,\n",
    "    id_vars=[\"LSOA Code\"],\n",
    "    value_vars=[col for col in df_filtered.columns if col.isdigit() and \"201501\" <= col <= \"201912\"],\n",
    "    var_name=\"Month\", \n",
    "    value_name=\"Count\"\n",
    ")\n",
    "\n",
    "# add a column named year\n",
    "df_long[\"Year\"] = df_long[\"Month\"].str[:4].astype(int)\n",
    "\n",
    "# calculate the total count of a year\n",
    "df_yearly = (\n",
    "    df_long\n",
    "    .groupby([\"LSOA Code\", \"Year\"])[\"Count\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"Count\": \"Theft Count\"})\n",
    ")\n",
    "\n",
    "print(df_yearly.shape)\n",
    "print(df_yearly.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58f25036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the lsoa in crime data, as a reference to select lsoas in London area\n",
    "london_lsoa = df_yearly[\"LSOA Code\"].unique() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cbe7b0",
   "metadata": {},
   "source": [
    "2. Population Density:\n",
    "Population density is provided wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "321ed4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24940, 3)\n",
      "   LSOA Code  Year  Population Density\n",
      "4  E01000006  2015        13158.253752\n",
      "5  E01000007  2015        10790.000000\n"
     ]
    }
   ],
   "source": [
    "# read density raw data\n",
    "den = pd.ExcelFile(\"https://raw.githubusercontent.com/meimao76/006assessment/refs/heads/master/data/sapelsoapopulationdensity20112022.xlsx\")\n",
    "sheet_names_den = den.sheet_names\n",
    "# print(sheet_names_den)\n",
    "# choose data sheet and filtered out the year\n",
    "df_den = den.parse(sheet_name=\"Mid-2011 to mid-2022 LSOA 2021\", skiprows=3, header=0)\n",
    "df_den.columns = df_den.columns.str.strip()\n",
    "df_den = df_den.rename(columns={\"LSOA 2021 Code\": \"LSOA Code\",\n",
    "                                \"Mid-2015: People per Sq Km\": \"2015\",\n",
    "                                \"Mid-2016: People per Sq Km\": \"2016\",\n",
    "                                \"Mid-2017: People per Sq Km\": \"2017\",\n",
    "                                \"Mid-2018: People per Sq Km\": \"2018\",\n",
    "                                \"Mid-2019: People per Sq Km\": \"2019\"})\n",
    "df_den = df_den[[\"LSOA Code\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\"]]\n",
    "\n",
    "# turn into long format\n",
    "den_long = pd.melt(df_den, \n",
    "                   id_vars=[\"LSOA Code\"], \n",
    "                   var_name=\"Year\", \n",
    "                   value_name=\"Population Density\")\n",
    "\n",
    "den_long[\"Year\"] = den_long[\"Year\"].astype(int)\n",
    "den_long[\"LSOA Code\"] = den_long[\"LSOA Code\"].astype(str)\n",
    "\n",
    "# select London areas\n",
    "london_den = den_long[den_long[\"LSOA Code\"].isin(london_lsoa)]\n",
    "\n",
    "print(london_den.shape)\n",
    "print(london_den.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf20afdb",
   "metadata": {},
   "source": [
    "3. Population and Vulnerable Group:\n",
    "Vulnerable group is defined as the proportion of people younger than 15 and elder than 65, which are considered as the potential vistims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5f6d198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24940, 4)\n",
      "       LSOA Code  Year  Population  Vulnerable_Ratio\n",
      "28767  E01000006  2015        1929          0.325557\n",
      "28768  E01000007  2015        2158          0.297498\n"
     ]
    }
   ],
   "source": [
    "# read population raw data\n",
    "pop = pd.ExcelFile(\"https://raw.githubusercontent.com/meimao76/006assessment/refs/heads/master/data/sapelsoabroadage20112022.xlsx\")\n",
    "sheet_names = pop.sheet_names\n",
    "# print(sheet_names)\n",
    "\n",
    "# defined the needed sheets and column\n",
    "target_sheets =['Mid-2015 LSOA 2021', 'Mid-2016 LSOA 2021', 'Mid-2017 LSOA 2021', 'Mid-2018 LSOA 2021', 'Mid-2019 LSOA 2021']\n",
    "target_year = {'Mid-2015 LSOA 2021': 2015, \n",
    "               'Mid-2016 LSOA 2021': 2016, \n",
    "               'Mid-2017 LSOA 2021': 2017, \n",
    "               'Mid-2018 LSOA 2021': 2018, \n",
    "               'Mid-2019 LSOA 2021': 2019}\n",
    "\n",
    "# combine all the data sheets\n",
    "pop_list=[]\n",
    "for sheet in target_sheets:\n",
    "    df_pop = pop.parse(sheet, skiprows=3, header=0)\n",
    "    df_pop.columns = df_pop.columns.str.strip()\n",
    "    df_pop = df_pop.rename(columns={\n",
    "        \"LSOA 2021 Code\": \"LSOA Code\",\n",
    "        \"Total\": \"Population\"\n",
    "    })\n",
    "    df_pop[\"Year\"] = target_year[sheet]\n",
    "    # calculating proportion of vulnerable group\n",
    "    df_pop[\"Vulnerable_Group\"] = df_pop[\"M65 and over\"] + df_pop[\"F65 and over\"] + df_pop[\"F0 to 15\"] + df_pop[\"M0 to 15\"] \n",
    "    df_pop[\"Vulnerable_Ratio\"] = df_pop[\"Vulnerable_Group\"] / df_pop[\"Population\"]\n",
    "\n",
    "    pop_list.append(df_pop[[\"LSOA Code\", \"Year\", \"Population\", \"Vulnerable_Ratio\"]])\n",
    "\n",
    "pop_fin = pd.concat(pop_list, ignore_index=True)\n",
    "\n",
    "# select data in London areas\n",
    "london_pop = pop_fin[pop_fin[\"LSOA Code\"].isin(london_lsoa)]\n",
    "\n",
    "print(london_pop.shape)\n",
    "print(london_pop.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7545f70b",
   "metadata": {},
   "source": [
    "4. House Price: Median house prices serve as an indicator of affluence and built environment quality, potentially affecting the occurrence and attractiveness of theft-related crime. Noted that this dataset in listed in 2011LSOA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "efa39a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23265, 3)\n",
      "     LSOA Code  Year  House Price\n",
      "136  E01000006  2015     196125.0\n",
      "137  E01000006  2016     349062.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_62920\\12043146.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  london_housing[\"House Price\"] = london_housing.groupby(\"LSOA Code\")[\"House Price\"].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_62920\\12043146.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  london_housing[\"House Price\"] = london_housing[\"House Price\"].fillna(london_housing[\"House Price\"].median())\n"
     ]
    }
   ],
   "source": [
    "# read raw house price data\n",
    "housing = pd.ExcelFile(\"https://raw.githubusercontent.com/meimao76/006assessment/refs/heads/master/data/hpssadataset46medianpricepaidforresidentialpropertiesbylsoa/median_price.xlsx\")\n",
    "sheet_names_housing = housing.sheet_names\n",
    "# print(sheet_names_housing)\n",
    "# select used data sheet\n",
    "df_housing = housing.parse(sheet_name=\"1a\", skiprows=5, header=0)\n",
    "df_housing.columns = df_housing.columns.str.strip()\n",
    "df_housing = df_housing.rename(columns={\"LSOA code\": \"LSOA Code\"})\n",
    "\n",
    "# turn into long format\n",
    "housing_long = pd.melt(df_housing, \n",
    "                  id_vars=[\"LSOA Code\"], \n",
    "                  var_name=\"Date\", \n",
    "                  value_name=\"House Price\")\n",
    "\n",
    "# extract the year out as a new column\n",
    "housing_long[\"House Price\"] = pd.to_numeric(housing_long[\"House Price\"], errors=\"coerce\")\n",
    "housing_long[\"Year\"] = housing_long[\"Date\"].str.extract(r\"(\\d{4})\")\n",
    "housing_long = housing_long.dropna(subset=[\"Year\"])\n",
    "housing_long[\"Year\"] = housing_long[\"Year\"].astype(int)\n",
    "housing_yearly = housing_long.groupby([\"LSOA Code\", \"Year\"])[\"House Price\"].mean().reset_index()\n",
    "\n",
    "# select data in London and between 2015-2019\n",
    "london_housing = housing_yearly[housing_yearly[\"LSOA Code\"].isin(london_lsoa)&\n",
    "    (housing_yearly[\"Year\"].between(2015, 2019))]\n",
    "\n",
    "# fill in the missing value in the dataset\n",
    "london_housing[\"House Price\"] = london_housing.groupby(\"LSOA Code\")[\"House Price\"].transform(lambda x: x.fillna(x.mean()))\n",
    "london_housing[\"House Price\"] = london_housing[\"House Price\"].fillna(london_housing[\"House Price\"].median())\n",
    "\n",
    "print(london_housing.shape)\n",
    "print(london_housing.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ab9505",
   "metadata": {},
   "source": [
    "5. Scores for the Indices of Deprivation:\n",
    "As crime domain is removed from the analysis, six remaining domain scores served as multiple indicators. Noted that this dataset in listed in 2011LSOA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d627ad1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4653, 7)\n",
      "   LSOA Code  Income Score (rate)  Employment Score (rate)  \\\n",
      "4  E01000006                0.117                    0.059   \n",
      "5  E01000007                0.207                    0.107   \n",
      "\n",
      "   Education, Skills and Training Score  \\\n",
      "4                                14.798   \n",
      "5                                11.385   \n",
      "\n",
      "   Health Deprivation and Disability Score  \\\n",
      "4                                   -0.359   \n",
      "5                                   -0.027   \n",
      "\n",
      "   Barriers to Housing and Services Score  Living Environment Score  \n",
      "4                                  45.171                    26.888  \n",
      "5                                  50.420                    25.995  \n"
     ]
    }
   ],
   "source": [
    "# read raw id score data\n",
    "IMD = pd.ExcelFile(\"https://raw.githubusercontent.com/meimao76/006assessment/refs/heads/master/data/File_5_-_IoD2019_Scores.xlsx\")\n",
    "sheet_names_IMD = IMD.sheet_names\n",
    "# print(sheet_names_IMD)\n",
    "# select data sheet\n",
    "df_IMD = IMD.parse(sheet_name=\"IoD2019 Scores\", header=0)\n",
    "df_IMD.columns = df_IMD.columns.str.strip()\n",
    "df_IMD = df_IMD.rename(columns={\"LSOA code (2011)\": \"LSOA Code\"})\n",
    "# select data in London areas\n",
    "df_IMD = df_IMD[df_IMD[\"LSOA Code\"].isin(london_lsoa)]\n",
    "# keep usefull columns\n",
    "keep_cols3 = [\"LSOA Code\", \"Income Score (rate)\", \n",
    "              \"Employment Score (rate)\", \n",
    "              \"Education, Skills and Training Score\", \n",
    "              \"Health Deprivation and Disability Score\", \n",
    "              \"Barriers to Housing and Services Score\", \n",
    "              \"Living Environment Score\"]\n",
    "IMD_fin = df_IMD[keep_cols3]\n",
    "\n",
    "print(IMD_fin.shape)\n",
    "print(IMD_fin.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ff3166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the lsoa list in cleaned ID dataset as the final analysed lsoas\n",
    "lsoa11 = IMD_fin[\"LSOA Code\"].unique()\n",
    "\n",
    "# filtered all the dataset again\n",
    "df_yearly = df_yearly[df_yearly[\"LSOA Code\"].isin(lsoa11)]\n",
    "london_pop = london_pop[london_pop[\"LSOA Code\"].isin(lsoa11)]\n",
    "london_den = london_den[london_den[\"LSOA Code\"].isin(lsoa11)]\n",
    "london_housing = london_housing[london_housing[\"LSOA Code\"].isin(lsoa11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0e976bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read lsoa 2011 boundaries\n",
    "lsoa_gdf = gpd.read_file(\"https://raw.githubusercontent.com/meimao76/006assessment/refs/heads/master/data/statistical-gis-boundaries-london/statistical-gis-boundaries-london/ESRI/LSOA_2011_London_gen_MHW.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6391f6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LSOA Code  tran_poi_count\n",
      "0  E01000007               5\n",
      "1  E01000008               1\n",
      "   LSOA Code  shop_poi_count\n",
      "0  E01000005               1\n",
      "1  E01000007              13\n"
     ]
    }
   ],
   "source": [
    "# get poi data from open street map\n",
    "# code from osmnx website\n",
    "\n",
    "place = \"London, UK\"\n",
    "tags1 = {\"railway\": \"station\", \"highway\": \"bus_stop\"}  # subway stations and bus stations\n",
    "tags2 = {\"shop\": True } # shops\n",
    "gdf1 = ox.features_from_place(place, tags1)\n",
    "gdf2 = ox.features_from_place(place, tags2)\n",
    "\n",
    "# set the same crs\n",
    "tran_poi_gdf = gdf1.to_crs(lsoa_gdf.crs)\n",
    "shop_poi_gdf = gdf2.to_crs(lsoa_gdf.crs)\n",
    "\n",
    "# change all types of geospatial features into points\n",
    "shop_poi_gdf[\"geometry\"] = shop_poi_gdf.geometry.centroid\n",
    "\n",
    "# join the transportation points with the lsoas\n",
    "joined_tran = gpd.sjoin(tran_poi_gdf, lsoa_gdf, how='inner', predicate='within')\n",
    "# counts the points within each lsoa\n",
    "tran_poi_count = joined_tran.groupby('LSOA11CD').size().reset_index(name='tran_poi_count')\n",
    "tran_poi_count = tran_poi_count.rename(columns={\"LSOA11CD\": \"LSOA Code\"})\n",
    "\n",
    "# same with the shop points\n",
    "joined_shop = gpd.sjoin(shop_poi_gdf, lsoa_gdf, how='inner', predicate='within')\n",
    "shop_poi_count = joined_shop.groupby('LSOA11CD').size().reset_index(name='shop_poi_count')\n",
    "shop_poi_count = shop_poi_count.rename(columns={\"LSOA11CD\": \"LSOA Code\"})\n",
    "\n",
    "print(tran_poi_count.head(2))\n",
    "print(shop_poi_count.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87f1435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data\n",
    "df_model = df_yearly.copy()\n",
    "df_model = df_model.merge(london_pop, on=[\"LSOA Code\", \"Year\"], how=\"left\")\n",
    "df_model = df_model.merge(london_den, on=[\"LSOA Code\", \"Year\"], how=\"left\")\n",
    "df_model = df_model.merge(london_housing, on=[\"LSOA Code\", \"Year\"], how=\"left\")\n",
    "df_model = df_model.merge(IMD_fin, on=\"LSOA Code\", how=\"left\")\n",
    "df_model = df_model.merge(tran_poi_count, on=\"LSOA Code\", how=\"left\")\n",
    "df_model[\"tran_poi_count\"] = df_model[\"tran_poi_count\"].fillna(0).astype(int)\n",
    "df_model = df_model.merge(shop_poi_count, on=\"LSOA Code\", how=\"left\")\n",
    "df_model[\"shop_poi_count\"] = df_model[\"shop_poi_count\"].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed53b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LSOA_Code  Year  Vulnerable_Ratio  Population_Density  House_Price  \\\n",
      "0  E01000006  2015          0.325557        13158.253752     196125.0   \n",
      "1  E01000006  2016          0.319872        12837.653479     349062.5   \n",
      "\n",
      "   Income_Score_rate  Employment_Score_rate  \\\n",
      "0              0.117                  0.059   \n",
      "1              0.117                  0.059   \n",
      "\n",
      "   Education,_Skills_and_Training_Score  \\\n",
      "0                                14.798   \n",
      "1                                14.798   \n",
      "\n",
      "   Health_Deprivation_and_Disability_Score  \\\n",
      "0                                   -0.359   \n",
      "1                                   -0.359   \n",
      "\n",
      "   Barriers_to_Housing_and_Services_Score  Living_Environment_Score  \\\n",
      "0                                  45.171                    26.888   \n",
      "1                                  45.171                    26.888   \n",
      "\n",
      "   tran_poi_count  shop_poi_count  Theft_Rate_per1k  \n",
      "0               0               0          1.555210  \n",
      "1               0               0          4.250797  \n",
      "(23265, 14)\n"
     ]
    }
   ],
   "source": [
    "# calculate crime rate\n",
    "df_model[\"Theft_Rate_per1k\"] = df_model[\"Theft Count\"] / df_model[\"Population\"] * 1000\n",
    "\n",
    "# delete the column that no longer used\n",
    "df_model = df_model.drop(columns=[\"Theft Count\", \"Population\"])\n",
    "\n",
    "# amend column names\n",
    "df_model.columns = df_model.columns.str.replace(\" \", \"_\")\n",
    "df_model.columns = df_model.columns.str.replace(r\"[()/]\", \"\", regex=True)\n",
    "\n",
    "print(df_model.head(2))\n",
    "print(df_model.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055843a",
   "metadata": {},
   "source": [
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1288cdda",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e204f0",
   "metadata": {},
   "source": [
    "## Discussion and conclusion\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1216c6b",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Boeing, G. 2024. “Modeling and Analyzing Urban Networks and Amenities with OSMnx.” Working paper. URL: https://geoffboeing.com/publications/osmnx-paper/\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
